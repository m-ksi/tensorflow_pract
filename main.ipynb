{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c8333c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.7.0-cp38-cp38-win_amd64.whl (430.8 MB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.1-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-12.0.0-py2.py3-none-win_amd64.whl (13.1 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting gast<0.5.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting flatbuffers<3.0,>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting keras<2.8,>=2.7.0rc0\n",
      "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.43.0-cp38-cp38-win_amd64.whl (3.4 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in d:\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.10.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.4.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=6233b6399ce3de8014ffdb25c13e5ee4f4d1b7ef6f894f28e8cfbba81816e906\n",
      "  Stored in directory: c:\\users\\maxim\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-4.2.4 flatbuffers-2.0 gast-0.4.0 google-auth-2.3.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.43.0 importlib-metadata-4.10.0 keras-2.7.0 keras-preprocessing-1.1.2 libclang-12.0.0 markdown-3.3.6 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.8 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tensorflow-io-gcs-filesystem-0.23.1 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dad12df",
   "metadata": {},
   "source": [
    "### I'm learning with Tensorflow Tutorial by Ren Zhang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa46ea98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pprint import pprint # prints objects nicely\n",
    "print(tf.__version__)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc60d184",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68f0ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=int8, numpy=1>,\n",
      " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>,\n",
      " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "scalar = tf.constant(1, dtype=tf.int8)\n",
    "vector = tf.constant([1, 2, 3], dtype=tf.float32)\n",
    "matrix = tf.constant(np.array([[1, 2], [3, 4]]), dtype=tf.float32)\n",
    "pprint([scalar, vector, matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b374d590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2])>\n",
      "2227990556336\n"
     ]
    }
   ],
   "source": [
    "print(matrix.shape)\n",
    "pprint(tf.shape(matrix))\n",
    "print(id(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fb7fb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(2, 2), dtype=int8, numpy=\n",
      "array([[1, 2],\n",
      "       [3, 4]], dtype=int8)>\n",
      "2227990582896\n"
     ]
    }
   ],
   "source": [
    "# tf.cast applys aperation\n",
    "matrix = tf.cast(matrix, dtype=tf.int8)\n",
    "pprint(matrix)\n",
    "print(id(matrix))\n",
    "# new id -> new tensor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca6deb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[0., 0.],\n",
      "       [0., 0.]], dtype=float32)>\n",
      "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
      "array([[0.6645621 , 0.44100678],\n",
      "       [0.3528825 , 0.46448255],\n",
      "       [0.03366041, 0.68467236]], dtype=float32)>\n",
      "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[1., 1.],\n",
      "       [1., 1.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "o = tf.zeros((2, 2))\n",
    "x = tf.random.uniform((3, 2))\n",
    "pprint(o)\n",
    "pprint(x)\n",
    "pprint(tf.ones_like(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39dc60ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_numpy = x.numpy()\n",
    "print(type(x_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403485f",
   "metadata": {},
   "source": [
    "#### Copying to deivces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4af4e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca66463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:CPU:0\n",
      "/job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    x_cpu = tf.identity(x)\n",
    "with tf.device('/gpu:0'):\n",
    "    x_gpu = tf.identity(x) # he can't find my gpu for some reason\n",
    "print(x_cpu.device)\n",
    "print(x_gpu.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd974fa2",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13401ee6",
   "metadata": {},
   "source": [
    "take tensors as inputs and give tensors as outputs\n",
    "\n",
    "basic math ops are overloaded by tensor ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4e08dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(), dtype=bool, numpy=True>\n"
     ]
    }
   ],
   "source": [
    "e = tf.random.uniform((3, 2), dtype=x.dtype)\n",
    "pprint(tf.math.reduce_all(x.__add__(e) == tf.add(x, e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bc90379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(), dtype=bool, numpy=True>\n"
     ]
    }
   ],
   "source": [
    "pprint(tf.math.reduce_all(x.__mul__(e) == tf.multiply(x, e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba61dc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(), dtype=bool, numpy=True>\n"
     ]
    }
   ],
   "source": [
    "pprint(tf.math.reduce_all(x.__matmul__(tf.transpose(e)) == tf.linalg.matmul(x, e, transpose_b=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea446df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(), dtype=int8, numpy=2>\n",
      "<tf.Tensor: shape=(2,), dtype=int8, numpy=array([3, 4], dtype=int8)>\n",
      "<tf.Tensor: shape=(1, 2), dtype=int8, numpy=array([[3, 4]], dtype=int8)>\n"
     ]
    }
   ],
   "source": [
    "#indexing is similar to numpy\n",
    "pprint(matrix[0, 1])\n",
    "pprint(matrix[1, :2])\n",
    "pprint(matrix[tf.newaxis, 1, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df4d4652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([5, 8])>\n",
      "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 7, 10])>\n",
      "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 6, 12])>\n",
      "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[18]])>\n",
      "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([1.5, 3. ])>\n",
      "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 4])>\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([3, 6])\n",
    "b = tf.constant([2, 2])\n",
    "pprint(tf.add(a, b))\n",
    "pprint(tf.add_n([a, b, b]))\n",
    "pprint(tf.multiply(a, b)) #elementwise multiplication\n",
    "#pprint(tf.matmul(a, b)) #error bc matrix multiplication\n",
    "pprint(tf.matmul(tf.reshape(a, [1, 2]), tf.reshape(b, [2, 1])))\n",
    "pprint(tf.divide(a, b))\n",
    "pprint(tf.math.subtract(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8650f9a6",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71a49b8",
   "metadata": {},
   "source": [
    "tensors are immutable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51773194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3, 2) dtype=float32, numpy=\n",
      "array([[0.6645621 , 0.44100678],\n",
      "       [0.3528825 , 0.46448255],\n",
      "       [0.03366041, 0.68467236]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "v = tf.Variable(x)\n",
    "pprint(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce4a86f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
      "array([[0.4416428 , 0.19448698],\n",
      "       [0.12452606, 0.21574403],\n",
      "       [0.00113302, 0.46877623]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# operators work same. output is a tensor!\n",
    "pprint(tf.square(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78543e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3, 2) dtype=float32, numpy=\n",
      "array([[0.4416428 , 0.19448698],\n",
      "       [0.12452606, 0.21574403],\n",
      "       [0.00113302, 0.46877623]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "#var update\n",
    "v.assign(tf.square(v))\n",
    "pprint(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f261b158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3, 2) dtype=float32, numpy=\n",
      "array([[-0.55835724, -0.805513  ],\n",
      "       [-0.8754739 , -0.784256  ],\n",
      "       [-0.998867  , -0.5312238 ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# also .assign_sub and .assign_add\n",
    "v.assign_sub(1 * tf.ones_like(v, dtype=v.dtype))\n",
    "pprint(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ad7892",
   "metadata": {},
   "source": [
    "#### Vars are typically used to represent parameters and states of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9753c425",
   "metadata": {},
   "source": [
    "### Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ccd1d",
   "metadata": {},
   "source": [
    "tf.GradientTape context helps to trace what happens inside to calc gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c09af788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([8.], dtype=float32)>,\n",
      " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([4], dtype=tf.float32)\n",
    "b = tf.Variable([5], dtype=tf.float32)\n",
    "\n",
    "def f(a, b, power=2, d=3):\n",
    "    return tf.pow(a, power) + d * b\n",
    "\n",
    "with tf.GradientTape(watch_accessed_variables=True) as tape:\n",
    "    c = f(a, b)\n",
    "pprint(tape.gradient(target=c, sources=[a, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d46f6742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=5.0>]\n"
     ]
    }
   ],
   "source": [
    "# we can also asc gradient to watch tensors too\n",
    "d = tf.constant(3, dtype=tf.float32)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(d)\n",
    "    c = f(a, b, d=d)\n",
    "pprint(tape.gradient(target=c, sources=[d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b2451fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([8.], dtype=float32)>]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-8a13c5c73073>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \"\"\"\n\u001b[0;32m   1031\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m       raise RuntimeError(\"A non-persistent GradientTape can only be used to \"\n\u001b[0m\u001b[0;32m   1033\u001b[0m                          \"compute one set of gradients (or jacobians)\")\n\u001b[0;32m   1034\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recording\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    c = f(a, b)\n",
    "pprint(tape.gradient(c, [a]))\n",
    "pprint(tape.gradient(c, [b]))\n",
    "# once we extact gradient from tape it will be released"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b229d765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([8.], dtype=float32)>]\n",
      "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape(persistent=True) as tape: # persistent allows to use it multiple times. better del after\n",
    "    c = f(a, b)\n",
    "pprint(tape.gradient(c, [a]))\n",
    "pprint(tape.gradient(c, [b]))\n",
    "del tape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d4c5a",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330eafd9",
   "metadata": {},
   "source": [
    "With tensors, variables, operations and automatic differentiation, we can start building\n",
    "models. Let's train a linear regression model with the gradient descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "505ba761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE at it    0 is 18.9390\n",
      "MSE at it  100 is 0.1633\n",
      "MSE at it  200 is 0.0389\n",
      "MSE at it  300 is 0.0104\n",
      "MSE at it  400 is 0.0030\n",
      "MSE at it  500 is 0.0009\n",
      "MSE at it  600 is 0.0003\n",
      "MSE at it  700 is 0.0001\n",
      "MSE at it  800 is 0.0000\n",
      "MSE at it  900 is 0.0000\n",
      "MSE at it 1000 is 0.0000\n",
      "<tf.Variable 'Variable:0' shape=(5, 1) dtype=float32, numpy=\n",
      "array([[2.7718204e-03],\n",
      "       [9.9988103e-01],\n",
      "       [2.0038643e+00],\n",
      "       [2.9949045e+00],\n",
      "       [3.9986048e+00]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# grount truth\n",
    "true_weights = tf.constant(list(range(5)), dtype=tf.float32)[:, tf.newaxis]\n",
    "\n",
    "# random training data\n",
    "x = tf.constant(tf.random.uniform((32, 5)), dtype=tf.float32)\n",
    "y = tf.constant(x @ true_weights, dtype=tf.float32) # what is @? prob matmul\n",
    "\n",
    "# parametes\n",
    "weights = tf.Variable(tf.random.uniform((5, 1)), dtype=tf.float32)\n",
    "\n",
    "for iteration in range(1001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_hat = tf.linalg.matmul(x, weights)\n",
    "        loss = tf.reduce_mean(tf.square(y-y_hat))\n",
    "        \n",
    "    if not iteration % 100:\n",
    "        print('MSE at it {:4d} is {:5.4f}'.format(iteration, loss))\n",
    "\n",
    "    gradients = tape.gradient(loss, weights)\n",
    "    weights.assign_add(-0.05 * gradients)\n",
    "pprint(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6bce64",
   "metadata": {},
   "source": [
    "## AutoGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9376ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87eb56bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        def tf__f(a, b, power=None, d=None):\n",
      "            with ag__.FunctionScope('f', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "                do_return = False\n",
      "                retval_ = ag__.UndefinedReturnValue()\n",
      "                try:\n",
      "                    do_return = True\n",
      "                    retval_ = (ag__.converted_call(ag__.ld(tf).pow, (ag__.ld(a), ag__.ld(power)), None, fscope) + (ag__.ld(d) * ag__.ld(b)))\n",
      "                except:\n",
      "                    do_return = False\n",
      "                    raise\n",
      "                return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def f(a, b, power=2, d=3):\n",
    "    return tf.pow(a, power)+ d * b\n",
    "converted_f = tf.autograph.to_graph(f)\n",
    "print(inspect.getsource(converted_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2eb2f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        def tf__cube(x):\n",
      "            with ag__.FunctionScope('cube', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "                do_return = False\n",
      "                retval_ = ag__.UndefinedReturnValue()\n",
      "                o = ag__.ld(x)\n",
      "\n",
      "                def get_state():\n",
      "                    return (o,)\n",
      "\n",
      "                def set_state(vars_):\n",
      "                    nonlocal o\n",
      "                    (o,) = vars_\n",
      "\n",
      "                def loop_body(itr):\n",
      "                    nonlocal o\n",
      "                    _ = itr\n",
      "                    o = ag__.ld(o)\n",
      "                    o *= x\n",
      "                _ = ag__.Undefined('_')\n",
      "                ag__.for_stmt(ag__.converted_call(ag__.ld(range), (2,), None, fscope), None, loop_body, get_state, set_state, ('o',), {'iterate_names': '_'})\n",
      "                try:\n",
      "                    do_return = True\n",
      "                    retval_ = 0\n",
      "                except:\n",
      "                    do_return = False\n",
      "                    raise\n",
      "                return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cube(x):\n",
    "    o = x\n",
    "    for _ in range(2):\n",
    "        o *= x\n",
    "    return 0\n",
    "\n",
    "converted_cube = tf.autograph.to_graph(cube)\n",
    "print(inspect.getsource(converted_cube))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38a4aeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        def tf__g(x):\n",
      "            with ag__.FunctionScope('g', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "                do_return = False\n",
      "                retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "                def get_state():\n",
      "                    return (do_return, retval_)\n",
      "\n",
      "                def set_state(vars_):\n",
      "                    nonlocal retval_, do_return\n",
      "                    (do_return, retval_) = vars_\n",
      "\n",
      "                def if_body():\n",
      "                    nonlocal retval_, do_return\n",
      "                    try:\n",
      "                        do_return = True\n",
      "                        retval_ = ag__.converted_call(ag__.ld(tf).square, (ag__.ld(x),), None, fscope)\n",
      "                    except:\n",
      "                        do_return = False\n",
      "                        raise\n",
      "\n",
      "                def else_body():\n",
      "                    nonlocal retval_, do_return\n",
      "                    try:\n",
      "                        do_return = True\n",
      "                        retval_ = ag__.ld(x)\n",
      "                    except:\n",
      "                        do_return = False\n",
      "                        raise\n",
      "                ag__.if_stmt(ag__.converted_call(ag__.ld(tf).reduce_any, ((ag__.ld(x) < 0),), None, fscope), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n",
      "                return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def g(x):\n",
    "    if tf.reduce_any(x<0):\n",
    "        return tf.square(x)\n",
    "    return x\n",
    "converted_g = tf.autograph.to_graph(g)\n",
    "print(inspect.getsource(converted_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9144b",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd7f3189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "tf_func_f = tf.function(autograph=False)(f)\n",
    "tf_func_g = tf.function(autograph=False)(converted_g)\n",
    "tf_func_g2 = tf.function(autograph=True)(g)\n",
    "print(tf_func_f.python_function is f)\n",
    "print(tf_func_g.python_function is converted_g)\n",
    "print(tf_func_g2.python_function is g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e2c427c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction tf__g(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=(3,)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(3,)\n"
     ]
    }
   ],
   "source": [
    "concrete_g = tf_func_g.get_concrete_function(x=tf.TensorSpec(shape=[3], dtype=tf.float32))\n",
    "print(concrete_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6cecc1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 1., 4.], dtype=float32)>\n",
      "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 1., 4.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "pprint(concrete_g(tf.constant([-1, 1, -2], dtype=tf.float32)))\n",
    "pprint(tf_func_g(tf.constant([-1, 1, -2], dtype=tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb7a7058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction f(a, b, power=2, d=3)\n",
      "  Args:\n",
      "    a: float32 Tensor, shape=(1,)\n",
      "    b: float32 Tensor, shape=(1,)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(1,)\n",
      "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>\n",
      "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>\n",
      "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>\n",
      "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>\n",
      "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>\n"
     ]
    }
   ],
   "source": [
    "concrete_f = tf_func_f.get_concrete_function(a=tf.TensorSpec(shape=[1], dtype=tf.float32), b=tf.TensorSpec(shape=[1], dtype=tf.float32))\n",
    "print(concrete_f)\n",
    "pprint(concrete_f(tf.constant(1.), tf.constant(2.)))\n",
    "pprint(tf_func_f(1., 2.)) # calls already created graph? maybe not\n",
    "pprint(tf_func_f(a=tf.constant(1.), b=2, power=2))\n",
    "pprint(tf_func_f(a=tf.constant(1.), b=2, d=3))\n",
    "pprint(tf_func_f(a=tf.constant(1.), b=2, d=3., power=3.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c943d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(tf_func_f._get_tracing_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b25e6562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ((TensorSpec(shape=(1,), dtype=tf.float32, name='a'), TensorSpec(shape=(1,), dtype=tf.float32, name='b'), 2, 3), {})\n",
      "1 ((1.0, 2.0, 2, 3), {})\n",
      "2 ((TensorSpec(shape=(), dtype=tf.float32, name='a'), 2, 2, 3), {})\n",
      "3 ((TensorSpec(shape=(), dtype=tf.float32, name='a'), 2, 3.0, 3.0), {})\n"
     ]
    }
   ],
   "source": [
    "for i, f in enumerate(tf_func_f._list_all_concrete_functions_for_serialization()):\n",
    "    print(i, f.structured_input_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "35fdb6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.function available as a decorator\n",
    "@tf.function(autograph=False)\n",
    "def square(x):\n",
    "    return x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "add5d361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x206beab5f40>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd3466a",
   "metadata": {},
   "source": [
    "### Linear Regression Once Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "416689f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38078f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE at it    0 is 17.4412\n",
      "MSE at it  200 is 0.0219\n",
      "MSE at it  400 is 0.0008\n",
      "MSE at it  600 is 0.0000\n",
      "MSE at it  800 is 0.0000\n",
      "MSE at it 1000 is 0.0000\n",
      "<tf.Variable 'Variable:0' shape=(5, 1) dtype=float32, numpy=\n",
      "array([[1.2918059e-03],\n",
      "       [9.9953943e-01],\n",
      "       [1.9996556e+00],\n",
      "       [2.9997427e+00],\n",
      "       [3.9998622e+00]], dtype=float32)>\n",
      "time took: 0.639289140701294 seconds\n"
     ]
    }
   ],
   "source": [
    "#baseline\n",
    "t0 = time.time()\n",
    "\n",
    "weights = tf.Variable(tf.random.uniform((5, 1)), dtype=tf.float32)\n",
    "x = tf.constant(tf.random.uniform((32, 5)), dtype=tf.float32)\n",
    "y = tf.constant(x @ true_weights, dtype=tf.float32) \n",
    "for iteration in range(1001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_hat = tf.linalg.matmul(x, weights)\n",
    "        loss = tf.reduce_mean(tf.square(y - y_hat))\n",
    "        \n",
    "    if not (iteration % 200):\n",
    "        print('MSE at it {:4d} is {:5.4f}'.format(iteration, loss))\n",
    "        \n",
    "    gradients = tape.gradient(loss, weights)\n",
    "    weights.assign_add(-0.05 * gradients)\n",
    "\n",
    "pprint(weights)\n",
    "\n",
    "print('time took: {} seconds'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "594a60ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE at it    0 is 21.9632\n",
      "MSE at it  200 is 0.0304\n",
      "MSE at it  400 is 0.0014\n",
      "MSE at it  600 is 0.0001\n",
      "MSE at it  800 is 0.0000\n",
      "MSE at it 1000 is 0.0000\n",
      "<tf.Variable 'Variable:0' shape=(5, 1) dtype=float32, numpy=\n",
      "array([[1.1034107e-03],\n",
      "       [1.0003557e+00],\n",
      "       [1.9990324e+00],\n",
      "       [3.0007610e+00],\n",
      "       [3.9986804e+00]], dtype=float32)>\n",
      "time took: 0.35553503036499023 seconds\n"
     ]
    }
   ],
   "source": [
    "# using @tf.function to speed things up\n",
    "t0 = time.time()\n",
    "\n",
    "weights = tf.Variable(tf.random.uniform((5, 1)), dtype=tf.float32)\n",
    "x = tf.constant(tf.random.uniform((32, 5)), dtype=tf.float32)\n",
    "y = tf.constant(x @ true_weights, dtype=tf.float32) \n",
    "\n",
    "@tf.function\n",
    "def train_step():\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_hat = tf.linalg.matmul(x, weights)\n",
    "        loss = tf.reduce_mean(tf.square(y - y_hat))\n",
    "    gradients = tape.gradient(loss, weights)\n",
    "    weights.assign_add(-0.05 * gradients)\n",
    "    return loss\n",
    "\n",
    "for iteration in range(1001):\n",
    "    loss = train_step()\n",
    "    if not (iteration % 200):\n",
    "        print('MSE at it {:4d} is {:5.4f}'.format(iteration, loss))\n",
    "\n",
    "pprint(weights)\n",
    "\n",
    "print('time took: {} seconds'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff18ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
